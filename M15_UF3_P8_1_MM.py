# -*- coding: utf-8 -*-
"""M15_UF3_P8_1_MM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-JK94FBEvt7KDcRSKQ2y2u36bCi3ViIk

# PARTE 1
¿Cómo se inicia el aprendizaje automático en Python?

#1.2 Iniciar Python y comprobar versiones
"""

# Consulta las versiones de las librerias
#-----Version de Python
import sys
print('Python: {}'.format(sys.version))
#-----Scipy
import scipy
print('scipy: {}'.format(scipy.__version__))
#-----Numpy
import numpy
print('numpy: {}'.format(numpy.__version__))
#-----Matplotlib
import matplotlib
print('matplotlib: {}'.format(matplotlib.__version__))
#-----Pandas
import pandas
print('pandas: {}'.format(pandas.__version__))
#-----Scikit-learn
import sklearn
print('sklearn: {}'.format(sklearn.__version__))

"""# 2.1 Importar bibliotecas"""

# Importar modulos y funciones
# Importa el módulo read_csv y scatter_matrix de la librería pandas
from pandas import read_csv
from pandas.plotting import scatter_matrix
from matplotlib import pyplot
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

"""# 2.2 Cargar conjunto de datos"""

# Cargar la DataFrame 
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv"
names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']
# Nombre de la DF: dataset
dataset = read_csv(url, names=names)

"""#3 Dimensiones del conjunto de datos"""

#--- 3.1 Dimensiones del conjunto de datos
#Informe de cunatas filas y columnas tiene la DataFrame "BD"
print(dataset.shape)

#--- 3.2 Datos
#head - Muestra por pantalla las 20 primeras filas de la BD 
print(dataset.head(20))

#--- 3.3 Resumen
#describe - Generar estadistica de la BD
print(dataset.describe())

#--- 3.4 Distrubucion de clases
#groupby - Agrupar la DF utilizando un parametro en este caso "by" para agrupar las columnas class 
# y ".size"devuelve un int del número de elementos que tipe este objecto. 
print(dataset.groupby('class').size())

"""#4. Visualización de datos"""

#--- 4.1 Graficos univariados
#plot - Gaficos de tipo diagrama de caja "box", "subplots" subtramas para las columnas, "layout" 
# para las filas, columnas del diseño de subparcelas.
dataset.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)
pyplot.show()

# hist histogramas de la 
dataset.hist()
pyplot.show()

#--- 4.2 Graficos multivariados
# Matriz de dispersion muestra una matriz de gráficos de dispersión cruzando las características
# cuantitativas de la BD.
scatter_matrix(dataset)
pyplot.show()

"""# 5. Evaluar algunos algoritmos"""

#--- 5.1 Crear un conjunto de datos de validación
#
array = dataset.values
X = array[:,0:4]
y = array[:,4]
X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)

#--- 5.3  Construir modelos 
# Algoritmos de verificación puntual
models = []
#append - Agregar filas de otras finales y que devuelvan un nuevo objecto.
# Algoritmos de regresión logística "LR"
models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))
# Algoritmos de análisis discriminabte lineal "LDA"
models.append(('LDA', LinearDiscriminantAnalysis()))
# Algoritmos de k vecino más proximo "KNN"
models.append(('KNN', KNeighborsClassifier()))
# Algoritmos de árboles de clasificación y regresión "CART"
models.append(('CART', DecisionTreeClassifier()))
# Algoritmos de bayes ingenuo gaussiano "NB"
models.append(('NB', GaussianNB()))
# Algoritmos de Soporta máquinas vectoriales "SVM"
models.append(('SVM', SVC(gamma='auto')))
# Evaluacion de cada modelo.
results = []
names = []
for name, model in models:
	kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)
	cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')
	results.append(cv_results)
	names.append(name)
	print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))

#--- 5.4 Seleccione el mejor modelo
# Comprovacion de los resultados de cada algoritmo mediante un diagrama de "box and whisker" caja 
# y bigote para cada distribución y comparación.
pyplot.boxplot(results, labels=names)
# Título del diagrama
pyplot.title('Algorithm Comparison')
pyplot.show()

"""# 6. Predicciones"""

#--- 6.1 Hacer predicciones
# Ajustar modelo en todos los conjuntos y hacer predicciones de datos validados 
model = SVC(gamma='auto')
model.fit(X_train, Y_train)
predictions = model.predict(X_validation)

#--- 6.2 Evaluar predicciones
print(accuracy_score(Y_validation, predictions))
print(confusion_matrix(Y_validation, predictions))
print(classification_report(Y_validation, predictions))

"""# PARTE 2
Cómo predecir resultados de clasificación o regresión
con modelos scikit-learn en Python.

# 1. Finalidad de modelo
"""

# Qué es un modelo final? Es un modelo que usa para hacer predicciones sobre nuevos datos

"""#2. Predecir modelos de clasificación"""

#--- Modelo de regresión logística
# Importar el modelo de regresión logística "LR" de la librería scikit-learn
from sklearn.linear_model import LogisticRegression
# Importar el modelo conjuntos aleatorios de la librería sklearn.datasets
from sklearn.datasets import make_blobs
#Generación de un conjunto de datos de clasificación 2d 
# (make_blobs) Conjunto de datos aleatorios.
# (n_samples)  Número total de puntos dividivo equitativamente entre grupos, valor predeterminado = 100.
# (centers)    Número de centros a generar o las ubicaciones de los centros fijos, valor predeterminado = 3.
# (n_features) Número de características de cada muestra, valor predeterminado = 2.
# (random_state) Semilla que se utiliza para generar números aleatorios, no tiene valor predeterminado.
# (X) Son las muestras generadas esta formado por n_samples, n_features.
# (y) Etiquetas de los números enteros que pertenecen al clúster de cada muestra esta formado por n_samples.
X, y = make_blobs(n_samples=100, centers=2, n_features=2, random_state=1)
# -fit  Ajuste del modelo de los datos X e y.
model = LogisticRegression()
model.fit(X, y)

"""#Predicciones de clases múltiples"""

#--- Usando el ejercicio anterior crearemos una predicción de múltiple
# new instances where we do not know the answer
Xnew, _ = make_blobs(n_samples=3, centers=2, n_features=2, random_state=1)
# Hacemos la nueva predicción 
ynew = model.predict(Xnew)
# Se muestran por pantalla las predicciones de entrada y salida que predice la clase para las tres nuevas instancias de datos.
for i in range(len(Xnew)):
	print("X=%s, Predicted=%s" % (Xnew[i], ynew[i]))

"""#Predicción de clase única"""

# Mdelo de regresión final
from sklearn.linear_model import LinearRegression
from sklearn.datasets import make_regression
# generar un conjunto de datos de regresión
X, y = make_regression(n_samples=100, n_features=2, noise=0.1)
# fmodelo final de fit
model = LinearRegression()
model.fit(X, y)
# Nueva definicion de instancia de datos
Xnew = [[-1.07296862, -0.52817175]]
# predicción
ynew = model.predict(Xnew)
# Muestra las entradas y salidas previstas
print("X=%s, Predicted=%s" % (Xnew[0], ynew[0]))

"""#Guarde y cargue modelos de aprendizaje automático en Python con scikit-learn"""

# Guardar modelo usando Pickle
import pandas
# Importar el modelo de selección de la librería sklearn
from sklearn import model_selection
# Importar el modelo de regresión logística "LR" de la librería sklearn.linear
from sklearn.linear_model import LogisticRegression
# El módulo pickle realiza lo que se llama serialización de objetos y convertir objetos a y de cadenas de bytes.
import pickle
# Importar base de datos
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
dataframe = pandas.read_csv(url, names=names)
# Creacion de array
array = dataframe.values
X = array[:,0:8]
Y = array[:,8]
test_size = 0.33
seed = 7
# Permite dividir un dataset en dos bloques, típicamente bloques destinados al entrenamiento y validación del modelo (llamemos a estos bloques "bloque de 
#entrenamiento " y "bloque de pruebas" para mantener la coherencia con el nombre de la función).
X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)
# Encajar el modelo en el set de entrenamiento
model = LogisticRegression()
model.fit(X_train, Y_train)
# Guardar el modelo en el disco
filename = 'finalized_model.sav'
pickle.dump(model, open(filename, 'wb'))
# Despues de un momento carga el modelo desde el disco
loaded_model = pickle.load(open(filename, 'rb'))
result = loaded_model.score(X_test, Y_test)
print(result)

# Guardar modelo usando joblib
import pandas
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
import joblib
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']
dataframe = pandas.read_csv(url, names=names)
array = dataframe.values
X = array[:,0:8]
Y = array[:,8]
test_size = 0.33
seed = 7
X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)
# Encajar el modelo en el set de entrenamiento
model = LogisticRegression()
model.fit(X_train, Y_train)
# Guardar el modelo en el disco
filename = 'finalized_model.sav'
joblib.dump(model, filename)
# Despues de un momento carga el modelo desde el disco
loaded_model = joblib.load(filename)
result = loaded_model.score(X_test, Y_test)
print(result)